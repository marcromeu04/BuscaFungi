# ğŸš€ GuÃ­a RÃ¡pida de Uso - BuscaFungi

## âš¡ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
pip install -r requirements.txt
```

### 2. Test RÃ¡pido (Recomendado)

```bash
# Test de interpolaciÃ³n meteorolÃ³gica (100 celdas, ~30 segundos)
python test_interpolation.py
```

**Esperado:**
- âœ… Descarga ~15 puntos de muestra
- âœ… Interpola a 100 celdas
- âœ… Muestra stats de precipitaciÃ³n y temperatura
- âœ… Genera `test_interpolation_output.csv`

### 3. Entrenamiento con Muestra

```bash
# Editar src/config.py primero:
# USE_SAMPLE = True
# SAMPLE_SIZE = 1000

python train.py
```

**Tiempo estimado:** ~5-10 minutos
- Grid: 1000 celdas
- Descarga GBIF: ~2 min
- Features ambientales: ~3 min
- Features meteorolÃ³gicas: ~2 min
- Entrenamiento: ~1 min

### 4. Entrenamiento Completo

```bash
# Editar src/config.py:
# USE_SAMPLE = False

python train.py
```

**Tiempo estimado:** ~1-2 horas
- Grid: 500,000 celdas
- Features ambientales: ~30 min (con logging cada 50 celdas)
- Features meteorolÃ³gicas: ~5 min (interpolaciÃ³n)
- Clustering: ~5 min
- Entrenamiento: ~10 min

---

## âš ï¸ Problemas Comunes

### Error 400 Bad Request en API MeteorolÃ³gica

**Causa:** Fecha muy reciente (API archive tiene delay de ~5-7 dÃ­as)

**SoluciÃ³n:**
```python
# âŒ MAL
target_date = datetime.now() - timedelta(days=2)  # Muy reciente

# âœ… BIEN
target_date = datetime.now() - timedelta(days=30)  # Datos disponibles
```

### Train.py tarda mucho en "estudiar parcelas"

**Causa:** ExtracciÃ³n de features ambientales (API calls)

**QuÃ© ver:**
- Logging cada 50 celdas: `ğŸ“ 50/1000 celdas (5.0%)`
- Si no ves nada: revisar logging level

**Para ver progress:**
```bash
# Asegurar logging visible
export PYTHONUNBUFFERED=1
python train.py 2>&1 | tee train.log
```

### No sÃ© si estÃ¡ usando interpolaciÃ³n

**DÃ³nde ver:**
- Busca en logs: `ğŸŒ§ï¸ Obteniendo meteo para N celdas`
- Debe decir: `Puntos de muestreo: ~100` (no 900k)
- Debe decir: `Interpolando a X celdas...`

---

## ğŸ“Š ConfiguraciÃ³n

### `src/config.py` - Opciones clave

```python
# Grid
GRID_RESOLUTION_KM = 1.0      # 1km (cambiar a 0.25 para 250m)
USE_SAMPLE = True              # False para grid completo
SAMPLE_SIZE = 1000             # Celdas si USE_SAMPLE=True

# RegiÃ³n
FOCUS_REGION = 'full_spain'   # 'leon', 'galicia', 'pirineos'

# Modelo
XGBOOST_PARAMS = {...}        # Tuning hiperparÃ¡metros

# Temporal (ventanas de agregaciÃ³n)
TEMPORAL_FEATURES = {
    'precipitation_windows': [7, 15, 20],
    'temperature_windows': [7, 15],
    'sunshine_windows': [7, 15, 20]
}

# Pseudo-ausencias
PSEUDO_ABSENCE_RATIO = 2.0    # Ratio ausencias:presencias
MIN_DISTANCE_KM = 10          # Distancia mÃ­nima a presencias
```

---

## ğŸ› Debug

### Ver todos los logs

```bash
# Cambiar en src/config.py:
LOG_LEVEL = 'DEBUG'  # en vez de 'INFO'
```

### Verificar imports

```python
import sys
sys.path.insert(0, 'src')

from src import BuscaFungiPipeline
from src.meteo import MeteoDataFetcher

print("âœ… Imports OK")
```

### Test paso a paso

```python
from src.grid import GridManager
from src.features import FeatureExtractor
from datetime import datetime

# 1. Grid
grid_mgr = GridManager()
grid = grid_mgr.create_grid(use_sample=True, sample_size=100)
print(f"âœ… Grid: {len(grid)} celdas")

# 2. Features (sin meteo)
feat_ext = FeatureExtractor()
features = feat_ext.extract_features_for_grid(
    grid,
    date=datetime.now() - timedelta(days=30),
    add_interactions=False
)
print(f"âœ… Features: {len(features.columns)} columnas")
```

---

## ğŸ’¡ Tips

### 1. Empezar pequeÃ±o
- USE_SAMPLE=True con SAMPLE_SIZE=100 para probar
- Una vez funcione, aumentar a 1000
- Solo al final usar grid completo

### 2. Usar cache
- Primera ejecuciÃ³n descarga datos
- Segunda ejecuciÃ³n usa cache (instantÃ¡neo)
- Cache en: `data/cache/meteo/*.parquet`

### 3. Fechas seguras
- Entrenamiento: observaciones tienen fechas histÃ³ricas (OK)
- PredicciÃ³n futura: usar `use_forecast=True`
- Test: usar fecha >= 30 dÃ­as atrÃ¡s

### 4. Monitoring
- Logging debe mostrar progreso cada ~30 segundos
- Si no ves nada por >2 minutos en muestra pequeÃ±a: problema
- Grid completo puede tardar horas en features ambientales

---

## ğŸ“š Siguiente Paso

Una vez entrenado:

```python
from src.pipeline import BuscaFungiPipeline
from datetime import datetime

pipeline = BuscaFungiPipeline()
# ... cargar modelos

# Predecir para maÃ±ana
predictions = pipeline.predict_for_date(
    target_date=datetime.now() + timedelta(days=1),
    species='Boletus edulis',
    use_forecast=True
)

predictions.to_csv('predicciones_maÃ±ana.csv')
```

**Ver README.md completo para mÃ¡s detalles**
