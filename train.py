#!/usr/bin/env python3
"""
BuscaFungi - Script de Entrenamiento
Entrena modelos SDM para hongos usando datos de GBIF
"""

import sys
import pandas as pd
from datetime import datetime
from pygbif import occurrences as occ, species as gbif_species

# A√±adir src al path
sys.path.insert(0, 'src')

from src.pipeline import BuscaFungiPipeline
from src import config


def fetch_gbif_observations(species_name, bounds, limit=500):
    """
    Descarga observaciones de GBIF para una especie
    """
    print(f"\nüîç Buscando: {species_name}")

    try:
        # Obtener taxon key
        result = gbif_species.name_backbone(name=species_name)
        if 'usageKey' not in result:
            print(f"  ‚ùå No encontrado en GBIF")
            return None

        taxon_key = result['usageKey']
        print(f"  ‚úÖ GBIF key: {taxon_key}")

        # Buscar observaciones
        results = occ.search(
            taxonKey=taxon_key,
            country='ES',
            hasCoordinate=True,
            hasGeospatialIssue=False,
            limit=limit,
            year='2015,2024'
        )

        count = results.get('count', 0)

        if count == 0:
            print(f"  ‚ö†Ô∏è 0 observaciones")
            return None

        # Parsear observaciones
        obs_list = []
        for obs in results.get('results', []):
            if 'decimalLatitude' in obs and 'decimalLongitude' in obs:
                lat = obs['decimalLatitude']
                lon = obs['decimalLongitude']

                if (bounds['lat_min'] <= lat <= bounds['lat_max'] and
                    bounds['lon_min'] <= lon <= bounds['lon_max']):

                    # Fecha
                    date = None
                    if 'eventDate' in obs:
                        try:
                            date = pd.to_datetime(obs['eventDate'])
                        except:
                            pass

                    if date is None and 'year' in obs and 'month' in obs:
                        year = obs['year']
                        month = obs.get('month', 1)
                        day = obs.get('day', 1)
                        try:
                            date = datetime(year, month, day)
                        except:
                            continue

                    if date is None:
                        continue

                    obs_list.append({
                        'species': species_name,
                        'lat': lat,
                        'lon': lon,
                        'date': date,
                        'observed': 1
                    })

        if obs_list:
            df = pd.DataFrame(obs_list)
            print(f"  ‚úÖ {len(df)} observaciones v√°lidas")
            return df
        else:
            print(f"  ‚ö†Ô∏è 0 observaciones v√°lidas")
            return None

    except Exception as e:
        print(f"  ‚ùå Error: {e}")
        return None


def main():
    """
    Pipeline principal de entrenamiento
    """
    print("\n" + "="*70)
    print("üçÑ BuscaFungi - Entrenamiento de Modelos SDM")
    print("="*70)

    # Configuraci√≥n
    print(f"\nüìç Regi√≥n: {config.FOCUS_REGION}")
    print(f"üéØ Resoluci√≥n: {config.GRID_RESOLUTION_KM}km")
    print(f"‚ö° Modo muestra: {config.USE_SAMPLE}")

    # Descargar observaciones de GBIF
    print("\n" + "="*70)
    print("üì• Descargando observaciones de GBIF")
    print("="*70)

    all_observations = []

    for species_name in config.SPECIES_CONFIG.keys():
        obs = fetch_gbif_observations(
            species_name,
            config.SPAIN_BOUNDS,
            limit=500
        )

        if obs is not None:
            all_observations.append(obs)

    if len(all_observations) == 0:
        print("\n‚ùå No se pudieron descargar observaciones. Abortando.")
        return

    observations_df = pd.concat(all_observations, ignore_index=True)

    print(f"\nüìä Total observaciones: {len(observations_df)}")
    print("\nDistribuci√≥n por especie:")
    print(observations_df['species'].value_counts())

    # Inicializar pipeline
    pipeline = BuscaFungiPipeline(
        use_sample=config.USE_SAMPLE,
        sample_size=config.SAMPLE_SIZE
    )

    # Ejecutar pipeline completo
    try:
        results = pipeline.run_full_pipeline(observations_df)

        # Guardar resultados
        print("\n" + "="*70)
        print("üíæ Guardando resultados...")
        print("="*70)

        pipeline.save_pipeline('outputs')

        print("\n‚úÖ ¬°Entrenamiento completado!")
        print("\nüìä Modelos entrenados:")
        for species in pipeline.models:
            print(f"  - {species}")

        print("\nüìÅ Archivos guardados en: outputs/")
        print("  - grid.csv")
        print("  - features.csv")
        print("  - observations.csv")
        print("  - models/*.joblib")

    except Exception as e:
        print(f"\n‚ùå Error durante entrenamiento: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
